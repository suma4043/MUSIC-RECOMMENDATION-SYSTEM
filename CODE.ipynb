{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f41611",
   "metadata": {},
   "source": [
    "# DOWNLOADING ALL REQUIRED MODULES FROM NATURAL LANGUAGE TOOLKIT  FOR PREPROSESSING THE SONG LYRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "958c3281",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gnand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gnand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gnand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gnand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure necessary NLTK data packages are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae333df4",
   "metadata": {},
   "source": [
    "# PREPOCESSING LYRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5f478aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_lyrics(lyrics):\n",
    "    # Tokenize\n",
    "    words = word_tokenize(lyrics)\n",
    "    # Convert to lower case, remove punctuation, and filter out stop words\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    # Lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1c3c5",
   "metadata": {},
   "source": [
    "# GETTING THE DIRECTORY AND COMBINING ALL THE CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0eea2407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist                   Title            Album        Date  \\\n",
       "0  Ariana Grande          ​thank u, next    thank u, next  2018-11-03   \n",
       "1  Ariana Grande                 7 rings    thank u, next  2019-01-18   \n",
       "2  Ariana Grande         ​God is a woman        Sweetener  2018-07-13   \n",
       "3  Ariana Grande            Side To Side  Dangerous Woman  2016-05-20   \n",
       "4  Ariana Grande  ​​no tears left to cry        Sweetener  2018-04-20   \n",
       "\n",
       "                                               Lyric  Year  Unnamed: 0  \n",
       "0  thought i'd end up with sean but he wasn't a m...  2018         NaN  \n",
       "1  yeah breakfast at tiffany's and bottles of bub...  2019         NaN  \n",
       "2  you you love it how i move you you love it how...  2018         NaN  \n",
       "3  ariana grande  nicki minaj i've been here all ...  2016         NaN  \n",
       "4  right now i'm in a state of mind i wanna be in...  2018         NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = \"SONGS\"\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d345694",
   "metadata": {},
   "source": [
    "# IDENTIFYING AND HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "820829f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "combined_df.isnull().sum()\n",
    "\n",
    "# Handle missing values (e.g., drop rows with missing lyrics)\n",
    "combined_df.dropna(subset=['Lyric'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd38c16",
   "metadata": {},
   "source": [
    "# DROP UNNECESSARY  COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b4201f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop(columns=['unnamed:_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b9c70",
   "metadata": {},
   "source": [
    "# STANDARDIZATION OF COLUMNS AND PREPROCESSING ODF LYRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a50fc3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>album</th>\n",
       "      <th>date</th>\n",
       "      <th>lyric</th>\n",
       "      <th>year</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018</td>\n",
       "      <td>thought end sean match wrote song ricky listen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019</td>\n",
       "      <td>yeah breakfast tiffany bottle bubble girl tatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018</td>\n",
       "      <td>love move love touch one said done believe god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>ariana grande nicki minaj night ariana day nic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018</td>\n",
       "      <td>right state mind wan na like time ai got tear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                   title            album        date  \\\n",
       "0  Ariana Grande          ​thank u, next    thank u, next  2018-11-03   \n",
       "1  Ariana Grande                 7 rings    thank u, next  2019-01-18   \n",
       "2  Ariana Grande         ​God is a woman        Sweetener  2018-07-13   \n",
       "3  Ariana Grande            Side To Side  Dangerous Woman  2016-05-20   \n",
       "4  Ariana Grande  ​​no tears left to cry        Sweetener  2018-04-20   \n",
       "\n",
       "                                               lyric  year  \\\n",
       "0  thought i'd end up with sean but he wasn't a m...  2018   \n",
       "1  yeah breakfast at tiffany's and bottles of bub...  2019   \n",
       "2  you you love it how i move you you love it how...  2018   \n",
       "3  ariana grande  nicki minaj i've been here all ...  2016   \n",
       "4  right now i'm in a state of mind i wanna be in...  2018   \n",
       "\n",
       "                                      cleaned_lyrics  \n",
       "0  thought end sean match wrote song ricky listen...  \n",
       "1  yeah breakfast tiffany bottle bubble girl tatt...  \n",
       "2  love move love touch one said done believe god...  \n",
       "3  ariana grande nicki minaj night ariana day nic...  \n",
       "4  right state mind wan na like time ai got tear ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names\n",
    "combined_df.columns = combined_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Check and remove duplicates\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Apply preprocessing to the lyrics column\n",
    "combined_df['cleaned_lyrics'] = combined_df['lyric'].apply(preprocess_lyrics)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df189b",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION WITH TFIDF*(Term Frequency-Inverse Document Frequency.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6983d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with the feature extraction and model building steps\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Feature Extraction with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_df['cleaned_lyrics'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4049df",
   "metadata": {},
   "source": [
    "# APPLY COSINE SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6871c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Similarity Matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31ceef",
   "metadata": {},
   "source": [
    "# FUNCTION FOR RECCOMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9434446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function for Recommendations\n",
    "def recommend_songs(song_title, top_n=5):\n",
    "    # Find the index of the song in the dataframe\n",
    "    song_idx = combined_df[combined_df['title'] == song_title].index[0]\n",
    "    # Get the similarity scores for this song\n",
    "    sim_scores = list(enumerate(cosine_sim[song_idx]))\n",
    "    # Sort by similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get the indices of the top_n most similar songs\n",
    "    top_indices = [idx for idx, score in sim_scores[1:top_n+1]]\n",
    "    # Return the titles of the most similar songs\n",
    "    return combined_df.iloc[top_indices][['artist', 'title']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bb757",
   "metadata": {},
   "source": [
    "# PRINTING THE RECCOMENDED SONGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23702999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOMENDED TOP 5 SONGS ARE:\n",
      "\n",
      "             artist                                              title\n",
      "133   Ariana Grande                                    7 rings (live)​\n",
      "76    Ariana Grande                                    7 rings (Remix)\n",
      "136   Ariana Grande  ​imagine / My Favorite Things / 7 rings / than...\n",
      "4229      Lady Gaga  Do What U Want (Red Ant & Amp Lexvas Deep Hous...\n",
      "3671     Katy Perry                                That’s More Like It\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "rsongs=recommend_songs('7 rings')\n",
    "print(\"RECOMENDED TOP 5 SONGS ARE:\\n\")\n",
    "print(rsongs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
